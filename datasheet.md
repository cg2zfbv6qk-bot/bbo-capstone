
This dataset was created to support a Bayesian Black-Box Optimisation (BBO) task under a limited query budget. The objective is to iteratively select input points that maximise unknown black-box functions while balancing exploration and exploitation. The dataset captures the sequential interaction between an optimisation algorithm and multiple benchmark functions over ten optimisation rounds.
The dataset consists of inputâ€“output query pairs collected across eight independent black-box functions. Each data point includes a continuous input vector (ranging from 2D to 8D) and a scalar output value returned by the function. The dataset is small by design, with fewer than 20 observations per function, reflecting realistic optimisation settings with expensive evaluations. Due to the iterative sampling strategy, the dataset is unevenly distributed across the input space, with denser coverage in regions identified as promising by the optimiser and sparse coverage elsewhere.
The data was collected sequentially over ten optimisation rounds. Initial points were generated using space-filling sampling methods (e.g. Sobol or Latin Hypercube sampling). Subsequent queries were selected using a Bayesian optimisation strategy based on a Gaussian Process surrogate model and an Upper Confidence Bound (UCB) acquisition function. Each new data point was generated by maximising the acquisition function given the current dataset. The collection process was automated and reproducible given the source code and random seeds.
No feature scaling or dimensionality reduction was applied to the input variables, as the optimisation strategy operates directly on the raw continuous input space. Output values were optionally normalised internally by the surrogate model for numerical stability. The dataset is intended for analysing and demonstrating sequential decision-making in black-box optimisation. It is not suitable for supervised learning benchmarks, large-scale model training, or tasks requiring independent and identically distributed (i.i.d.) samples.
The dataset is stored as part of a public GitHub repository associated with the BBO capstone project. It is provided for educational and research purposes only. The dataset is maintained by the project author and will not be updated after submission, as it represents a fixed optimisation trace rather than a continuously growing data source.
